{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename)) # prints the full path of each file\nimport tensorflow as tf\nimport tensorflow_decision_forests as tfdf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:10:14.466504Z","iopub.execute_input":"2024-11-24T16:10:14.467023Z","iopub.status.idle":"2024-11-24T16:10:31.207090Z","shell.execute_reply.started":"2024-11-24T16:10:14.466982Z","shell.execute_reply":"2024-11-24T16:10:31.205859Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**Load DataSet**","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\ntrain_df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:15:33.977458Z","iopub.execute_input":"2024-11-24T16:15:33.978767Z","iopub.status.idle":"2024-11-24T16:15:34.002725Z","shell.execute_reply.started":"2024-11-24T16:15:33.978723Z","shell.execute_reply":"2024-11-24T16:15:34.001585Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"#Prepare dataset:\n#Tokenize the name\n#\"Braund, Mr. Owen Harris\" will become [\"Braund\", \"Mr.\", \"Owen\", \"Harris\"]\n#Extract any prefix ticket\n#\"STON/O2. 3101282\" will become \"STON/O2. and 310282","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:10:31.256660Z","iopub.execute_input":"2024-11-24T16:10:31.257183Z","iopub.status.idle":"2024-11-24T16:10:31.287994Z","shell.execute_reply.started":"2024-11-24T16:10:31.257132Z","shell.execute_reply":"2024-11-24T16:10:31.286564Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#function that takes in a dataframe df as input\ndef preprocess(df):\n\n    #take copy of data\n    df = df.copy()\n\n    #strip special characters, join in single string w spaces\n    def normalize_name(x):\n        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n\n    #extracts last part of ticket\n    def ticket_number(x):\n        return x.split(\" \")[-1]\n    #extracts first part of ticket, in not then 'none'\n    def ticket_item(x):\n        items = x.split(\" \")\n        if len(items) == 1:\n            return \"NONE\"\n        return \"_\".join(items[0:-1])\n\n    #new dataframe\n    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)                     \n    return df\n\n#run preproccess function above on training and testing functions\npreprocessed_train_df = preprocess(train_df)\npreprocessed_serving_df = preprocess(serving_df)\n\npreprocessed_train_df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:10:31.290989Z","iopub.execute_input":"2024-11-24T16:10:31.291483Z","iopub.status.idle":"2024-11-24T16:10:31.324807Z","shell.execute_reply.started":"2024-11-24T16:10:31.291430Z","shell.execute_reply":"2024-11-24T16:10:31.323644Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                              Name     Sex   Age  SibSp  \\\n0                            Braund Mr Owen Harris    male  22.0      1   \n1  Cumings Mrs John Bradley Florence Briggs Thayer  female  38.0      1   \n2                             Heikkinen Miss Laina  female  26.0      0   \n3         Futrelle Mrs Jacques Heath Lily May Peel  female  35.0      1   \n4                           Allen Mr William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked Ticket_number Ticket_item  \n0      0         A/5 21171   7.2500   NaN        S         21171         A/5  \n1      0          PC 17599  71.2833   C85        C         17599          PC  \n2      0  STON/O2. 3101282   7.9250   NaN        S       3101282    STON/O2.  \n3      0            113803  53.1000  C123        S        113803        NONE  \n4      0            373450   8.0500   NaN        S        373450        NONE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Ticket_number</th>\n      <th>Ticket_item</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund Mr Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>21171</td>\n      <td>A/5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings Mrs John Bradley Florence Briggs Thayer</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>17599</td>\n      <td>PC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen Miss Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3101282</td>\n      <td>STON/O2.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle Mrs Jacques Heath Lily May Peel</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>113803</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen Mr William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>373450</td>\n      <td>NONE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"#remove some features: we dont want train model on passenegrID,and ticket\ninput_features = list(preprocessed_train_df.columns)\ninput_features.remove(\"Ticket\")\ninput_features.remove(\"PassengerId\")\ninput_features.remove(\"Survived\")\n#input_features.remove(\"Ticket_number\")\n\nprint(f\"Input features: {input_features}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:10:31.326196Z","iopub.execute_input":"2024-11-24T16:10:31.326527Z","iopub.status.idle":"2024-11-24T16:10:31.339666Z","shell.execute_reply.started":"2024-11-24T16:10:31.326496Z","shell.execute_reply":"2024-11-24T16:10:31.338451Z"}},"outputs":[{"name":"stdout","text":"Input features: ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'Ticket_number', 'Ticket_item']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def tokenize_names(features, labels=None):\n    #Divde the names into individual tokens\n    features[\"Name\"] =  tf.strings.split(features[\"Name\"])\n    return features, labels\n\n#tfdf.keras.pd_dataframe_to_tf_dataset : converts pandas df to tf df\n#label = survived : Specifies the label column for supervised learning\n#Applies the tokenize_names function to each row in the dataset\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_train_df,label=\"Survived\").map(tokenize_names)\ntest_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(tokenize_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:10:31.341074Z","iopub.execute_input":"2024-11-24T16:10:31.341453Z","iopub.status.idle":"2024-11-24T16:10:31.790861Z","shell.execute_reply.started":"2024-11-24T16:10:31.341398Z","shell.execute_reply":"2024-11-24T16:10:31.789666Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#First training a GradientBoostedTreesModel model with the default parameterst\n\n\n#initialize model\n\n#keras.GradientBoostedTreesModel: Ensemble learning algorithm combining decision trees\n#works by iteratively building trees to minimize the error of previous trees\nmodel = tfdf.keras.GradientBoostedTreesModel(\n    \n    #Reduces amount of logging informationfor simplicity\n    verbose=0,\n    \n    #Specifies the features to use for training\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    #other features ignored\n    exclude_non_specified_features=True,\n    #Sets a fixed random seed for reproducibility\n    random_seed=1234,\n)\n\n#Trains the Gradient Boosted Trees model on the training dataset \nmodel.fit(train_ds)\n\n#Evaluates the model's performance using the training dataset and prints\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:10:31.791990Z","iopub.execute_input":"2024-11-24T16:10:31.792331Z","iopub.status.idle":"2024-11-24T16:10:42.432998Z","shell.execute_reply.started":"2024-11-24T16:10:31.792297Z","shell.execute_reply":"2024-11-24T16:10:42.431714Z"}},"outputs":[{"name":"stderr","text":"[WARNING 24-11-24 16:10:31.8452 UTC gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 24-11-24 16:10:31.8461 UTC gradient_boosted_trees.cc:1851] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 24-11-24 16:10:31.8461 UTC gradient_boosted_trees.cc:1865] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 24-11-24 16:10:36.9330 UTC kernel.cc:1233] Loading model from path /tmp/tmp1jhfyyh1/model/ with prefix 1115d0d7150c4a6e\n[INFO 24-11-24 16:10:36.9389 UTC quick_scorer_extended.cc:911] The binary was compiled without AVX2 support, but your CPU supports it. Enable it for faster model inference.\n[INFO 24-11-24 16:10:36.9394 UTC abstract_model.cc:1362] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n[INFO 24-11-24 16:10:36.9394 UTC kernel.cc:1061] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8260869383811951 Loss:0.8608942627906799\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#Train model with improved default parameters\n\nmodel = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0, \n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features=True,\n    \n    #Enables computation of permutation-based feature importance\n    #slower but provides a deep understanding of the feature contributions\n    #compute_permutation_variable_importance=True,\n\n    # Uncommenting this could override the manual parameters\n    # Change the default hyper-parameters\n    # hyperparameter_template=\"benchmark_rank1@v1\",\n    \n    #num_trees=1000,\n    #tuner=tuner\n\n    # Sets the min number of examples node for further splitting. Lower values more granular splits\n    min_examples=1,\n\n    #selects splits based on randomized subsets of categories\n    categorical_algorithm=\"RANDOM\",\n\n    #Limits the depth of the trees to control overfitting\n    #max_depth=4,\n    \n    #aka learning rate: contribution of each tree to final prediction. Smaller = more accurate, slower training\n    shrinkage=0.05,\n\n    #proportion of features considered for each split, reduces training time\n    #num_candidate_attributes_ratio=0.2,\n\n    #creates splits that involve linear combinations of features. To handle high-dimensional data effectively\n    split_axis=\"SPARSE_OBLIQUE\",\n    \n    #normalize data using min_max metho data before splitting\n    sparse_oblique_normalization=\"MIN_MAX\",\n    \n    #higher val = complex splits,capture more subtle patterns\n    sparse_oblique_num_projections_exponent=2.0,\n\n    #number of trees in ensemble, incr accuracy\n    num_trees=2000,\n\n    #ratio of training data reserved for validation\n    #validation_ratio=0.0,\n    \n    random_seed=1234,\n    )\n\n#train model\nmodel.fit(train_ds)\n\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:10:42.434317Z","iopub.execute_input":"2024-11-24T16:10:42.434616Z","iopub.status.idle":"2024-11-24T16:10:43.751734Z","shell.execute_reply.started":"2024-11-24T16:10:42.434585Z","shell.execute_reply":"2024-11-24T16:10:43.750593Z"}},"outputs":[{"name":"stderr","text":"[WARNING 24-11-24 16:10:42.4484 UTC gradient_boosted_trees.cc:1840] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 24-11-24 16:10:42.4484 UTC gradient_boosted_trees.cc:1851] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 24-11-24 16:10:42.4484 UTC gradient_boosted_trees.cc:1865] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 24-11-24 16:10:43.4236 UTC kernel.cc:1233] Loading model from path /tmp/tmpf0d9557h/model/ with prefix d2689b95109f4412\n[INFO 24-11-24 16:10:43.4316 UTC decision_forest.cc:734] Model loaded with 40 root(s), 2106 node(s), and 10 input feature(s).\n[INFO 24-11-24 16:10:43.4316 UTC kernel.cc:1061] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.782608687877655 Loss:1.0586705207824707\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:10:43.753000Z","iopub.execute_input":"2024-11-24T16:10:43.753334Z","iopub.status.idle":"2024-11-24T16:10:43.769166Z","shell.execute_reply.started":"2024-11-24T16:10:43.753302Z","shell.execute_reply":"2024-11-24T16:10:43.767869Z"}},"outputs":[{"name":"stdout","text":"Model: \"gradient_boosted_trees_model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n=================================================================\nTotal params: 1 (1.00 Byte)\nTrainable params: 0 (0.00 Byte)\nNon-trainable params: 1 (1.00 Byte)\n_________________________________________________________________\nType: \"GRADIENT_BOOSTED_TREES\"\nTask: CLASSIFICATION\nLabel: \"__LABEL\"\n\nInput Features (11):\n\tAge\n\tCabin\n\tEmbarked\n\tFare\n\tName\n\tParch\n\tPclass\n\tSex\n\tSibSp\n\tTicket_item\n\tTicket_number\n\nNo weights\n\nVariable Importance: INV_MEAN_MIN_DEPTH:\n    1.           \"Sex\"  0.585997 ################\n    2.           \"Age\"  0.364636 #######\n    3.          \"Fare\"  0.266191 ###\n    4.          \"Name\"  0.207054 #\n    5.        \"Pclass\"  0.179191 \n    6. \"Ticket_number\"  0.178806 \n    7.      \"Embarked\"  0.177803 \n    8.   \"Ticket_item\"  0.177009 \n    9.         \"Parch\"  0.175276 \n   10.         \"SibSp\"  0.171694 \n\nVariable Importance: NUM_AS_ROOT:\n    1.  \"Sex\" 34.000000 ################\n    2. \"Name\"  6.000000 \n\nVariable Importance: NUM_NODES:\n    1.           \"Age\" 510.000000 ################\n    2.          \"Fare\" 298.000000 #########\n    3.          \"Name\" 60.000000 #\n    4.   \"Ticket_item\" 47.000000 #\n    5.           \"Sex\" 40.000000 #\n    6.         \"Parch\" 22.000000 \n    7. \"Ticket_number\" 20.000000 \n    8.      \"Embarked\" 15.000000 \n    9.        \"Pclass\" 15.000000 \n   10.         \"SibSp\"  6.000000 \n\nVariable Importance: SUM_SCORE:\n    1.           \"Sex\" 482.453470 ################\n    2.           \"Age\" 390.670218 ############\n    3.          \"Fare\" 321.170935 ##########\n    4.          \"Name\" 102.043860 ###\n    5.        \"Pclass\" 26.605919 \n    6.   \"Ticket_item\" 22.954813 \n    7. \"Ticket_number\" 17.413948 \n    8.      \"Embarked\"  8.969861 \n    9.         \"Parch\"  6.947528 \n   10.         \"SibSp\"  0.455899 \n\n\n\nLoss: BINOMIAL_LOG_LIKELIHOOD\nValidation loss value: 1.05867\nNumber of trees per iteration: 1\nNode format: NOT_SET\nNumber of trees: 40\nTotal number of nodes: 2106\n\nNumber of nodes by tree:\nCount: 40 Average: 52.65 StdDev: 4.2869\nMin: 41 Max: 61 Ignored: 0\n----------------------------------------------\n[ 41, 42)  2   5.00%   5.00% ##\n[ 42, 43)  0   0.00%   5.00%\n[ 43, 44)  0   0.00%   5.00%\n[ 44, 45)  0   0.00%   5.00%\n[ 45, 46)  0   0.00%   5.00%\n[ 46, 47)  0   0.00%   5.00%\n[ 47, 48)  4  10.00%  15.00% ####\n[ 48, 49)  0   0.00%  15.00%\n[ 49, 50)  3   7.50%  22.50% ###\n[ 50, 51)  0   0.00%  22.50%\n[ 51, 52)  4  10.00%  32.50% ####\n[ 52, 53)  0   0.00%  32.50%\n[ 53, 54) 11  27.50%  60.00% ##########\n[ 54, 55)  0   0.00%  60.00%\n[ 55, 56) 10  25.00%  85.00% #########\n[ 56, 57)  0   0.00%  85.00%\n[ 57, 58)  2   5.00%  90.00% ##\n[ 58, 59)  0   0.00%  90.00%\n[ 59, 60)  3   7.50%  97.50% ###\n[ 60, 61]  1   2.50% 100.00% #\n\nDepth by leafs:\nCount: 1073 Average: 4.84623 StdDev: 0.454477\nMin: 2 Max: 5 Ignored: 0\n----------------------------------------------\n[ 2, 3)   1   0.09%   0.09%\n[ 3, 4)  38   3.54%   3.63%\n[ 4, 5)  86   8.01%  11.65% #\n[ 5, 5] 948  88.35% 100.00% ##########\n\nNumber of training obs by leaf:\nCount: 1073 Average: 29.7856 StdDev: 71.8675\nMin: 1 Max: 458 Ignored: 0\n----------------------------------------------\n[   1,  23) 846  78.84%  78.84% ##########\n[  23,  46)  62   5.78%  84.62% #\n[  46,  69)  48   4.47%  89.10% #\n[  69,  92)  21   1.96%  91.05%\n[  92, 115)  10   0.93%  91.99%\n[ 115, 138)  15   1.40%  93.38%\n[ 138, 161)  23   2.14%  95.53%\n[ 161, 184)   6   0.56%  96.09%\n[ 184, 207)   3   0.28%  96.37%\n[ 207, 230)   4   0.37%  96.74%\n[ 230, 252)   1   0.09%  96.83%\n[ 252, 275)   1   0.09%  96.92%\n[ 275, 298)   2   0.19%  97.11%\n[ 298, 321)   2   0.19%  97.30%\n[ 321, 344)   0   0.00%  97.30%\n[ 344, 367)   9   0.84%  98.14%\n[ 367, 390)   6   0.56%  98.70%\n[ 390, 413)   9   0.84%  99.53%\n[ 413, 436)   4   0.37%  99.91%\n[ 436, 458]   1   0.09% 100.00%\n\nAttribute in nodes:\n\t510 : Age [NUMERICAL]\n\t298 : Fare [NUMERICAL]\n\t60 : Name [CATEGORICAL_SET]\n\t47 : Ticket_item [CATEGORICAL]\n\t40 : Sex [CATEGORICAL]\n\t22 : Parch [NUMERICAL]\n\t20 : Ticket_number [CATEGORICAL]\n\t15 : Pclass [NUMERICAL]\n\t15 : Embarked [CATEGORICAL]\n\t6 : SibSp [NUMERICAL]\n\nAttribute in nodes with depth <= 0:\n\t34 : Sex [CATEGORICAL]\n\t6 : Name [CATEGORICAL_SET]\n\nAttribute in nodes with depth <= 1:\n\t48 : Age [NUMERICAL]\n\t34 : Sex [CATEGORICAL]\n\t25 : Fare [NUMERICAL]\n\t6 : Name [CATEGORICAL_SET]\n\t5 : Pclass [NUMERICAL]\n\t2 : Ticket_number [CATEGORICAL]\n\nAttribute in nodes with depth <= 2:\n\t121 : Age [NUMERICAL]\n\t74 : Fare [NUMERICAL]\n\t34 : Sex [CATEGORICAL]\n\t19 : Name [CATEGORICAL_SET]\n\t8 : Ticket_number [CATEGORICAL]\n\t8 : Embarked [CATEGORICAL]\n\t6 : Pclass [NUMERICAL]\n\t6 : Parch [NUMERICAL]\n\t3 : Ticket_item [CATEGORICAL]\n\nAttribute in nodes with depth <= 3:\n\t261 : Age [NUMERICAL]\n\t164 : Fare [NUMERICAL]\n\t36 : Sex [CATEGORICAL]\n\t35 : Name [CATEGORICAL_SET]\n\t16 : Ticket_item [CATEGORICAL]\n\t13 : Ticket_number [CATEGORICAL]\n\t12 : Embarked [CATEGORICAL]\n\t11 : Parch [NUMERICAL]\n\t9 : Pclass [NUMERICAL]\n\t2 : SibSp [NUMERICAL]\n\nAttribute in nodes with depth <= 5:\n\t510 : Age [NUMERICAL]\n\t298 : Fare [NUMERICAL]\n\t60 : Name [CATEGORICAL_SET]\n\t47 : Ticket_item [CATEGORICAL]\n\t40 : Sex [CATEGORICAL]\n\t22 : Parch [NUMERICAL]\n\t20 : Ticket_number [CATEGORICAL]\n\t15 : Pclass [NUMERICAL]\n\t15 : Embarked [CATEGORICAL]\n\t6 : SibSp [NUMERICAL]\n\nCondition type in nodes:\n\t851 : ObliqueCondition\n\t135 : ContainsBitmapCondition\n\t47 : ContainsCondition\nCondition type in nodes with depth <= 0:\n\t38 : ContainsBitmapCondition\n\t2 : ContainsCondition\nCondition type in nodes with depth <= 1:\n\t78 : ObliqueCondition\n\t40 : ContainsBitmapCondition\n\t2 : ContainsCondition\nCondition type in nodes with depth <= 2:\n\t207 : ObliqueCondition\n\t58 : ContainsBitmapCondition\n\t14 : ContainsCondition\nCondition type in nodes with depth <= 3:\n\t447 : ObliqueCondition\n\t83 : ContainsBitmapCondition\n\t29 : ContainsCondition\nCondition type in nodes with depth <= 5:\n\t851 : ObliqueCondition\n\t135 : ContainsBitmapCondition\n\t47 : ContainsCondition\n\nTraining logs:\nNumber of iteration to final model: 40\n\tIter:1 train-loss:1.264594 valid-loss:1.360749  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:2 train-loss:1.210623 valid-loss:1.320363  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:3 train-loss:1.160657 valid-loss:1.281972  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:4 train-loss:1.116982 valid-loss:1.250548  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:5 train-loss:1.075170 valid-loss:1.221467  train-accuracy:0.807259 valid-accuracy:0.760870\n\tIter:6 train-loss:1.035656 valid-loss:1.199482  train-accuracy:0.822278 valid-accuracy:0.760870\n\tIter:16 train-loss:0.787670 valid-loss:1.088161  train-accuracy:0.903630 valid-accuracy:0.771739\n\tIter:26 train-loss:0.647960 valid-loss:1.065191  train-accuracy:0.922403 valid-accuracy:0.782609\n\tIter:36 train-loss:0.557737 valid-loss:1.071260  train-accuracy:0.922403 valid-accuracy:0.782609\n\tIter:46 train-loss:0.494259 valid-loss:1.063639  train-accuracy:0.927409 valid-accuracy:0.771739\n\tIter:56 train-loss:0.443537 valid-loss:1.070069  train-accuracy:0.939925 valid-accuracy:0.760870\n\tIter:66 train-loss:0.404514 valid-loss:1.081874  train-accuracy:0.949937 valid-accuracy:0.760870\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#Predictions\ndef prediction_format(model, threshold=0.5):\n    pb_survive = model.predict(test_ds, verbose=0)[:,0]\n    return pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        #cutoff probability = threshold = 0.5\n        \"Survived\": (pb_survive >= threshold).astype(int)\n    })\n    \ndef make_submission(predictions):\n    path=\"/kaggle/working/submission.csv\"\n    predictions.to_csv(path, index=False)\n    print(f\"Submission exported to {path}\")\n\npredictions = prediction_format(model)\nmake_submission(predictions)\n!head /kaggle/working/submission.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T16:15:40.360094Z","iopub.execute_input":"2024-11-24T16:15:40.360512Z","iopub.status.idle":"2024-11-24T16:15:41.609814Z","shell.execute_reply.started":"2024-11-24T16:15:40.360476Z","shell.execute_reply":"2024-11-24T16:15:41.608038Z"}},"outputs":[{"name":"stdout","text":"Submission exported to /kaggle/working/submission.csv\nPassengerId,Survived\n892,0\n893,0\n894,0\n895,0\n896,0\n897,0\n898,0\n899,0\n900,1\n","output_type":"stream"}],"execution_count":14}]}